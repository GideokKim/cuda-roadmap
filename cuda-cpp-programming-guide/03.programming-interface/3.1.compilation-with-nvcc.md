## 3.1. NVCC로의 컴파일

커널은 *PTX(Parallel Thread Execution, PTX는 NVIDIA 병렬 스레드 실행 가상머신의 명령어 집합 아키텍처이다.)*라고 불리는 CUDA 명령어 집합 아키텍처를 사용하여 작성할 수 있으며, 이는 PTX 참조 매뉴얼에 설명되어 있습니다. 그러나 일반적으로 C++와 같은 고급 프로그래밍 언어를 사용하는 것이 더 효과적입니다. 두 경우 모두, 커널은 디바이스에서 실행하기 위해 `nvcc`에 의해 이진 코드로 컴파일되어야 합니다.

`nvcc`는 C++ 또는 `PTX` 코드를 컴파일하는 데 도움을 주는 컴파일러 드라이버입니다: 간단하고 익숙한 명령줄 옵션을 제공하고 이를 구현하는 도구 집합을 호출합니다. 이 섹션은 `nvcc` 워크플로우와 명령줄 옵션에 대한 개요를 제공합니다. 완전한 설명은 `nvcc` 사용자 매뉴얼에서 찾을 수 있습니다.

### 3.1.1. 컴파일 워크플로우

#### 3.1.1.1. 오프라인 컴파일

`nvcc`로 컴파일된 소스 파일은 호스트 코드(즉, 호스트에서 실행되는 코드)와 디바이스 코드(즉, 디바이스에서 실행되는 코드)를 혼합하여 포함할 수 있습니다. `nvcc`의 기본 워크플로우는 장치 코드를 호스트 코드와 분리한 다음:

> 디바이스 코드를 어셈블리 형태(*PTX* 코드) 및/또는 이진 형태(*cubin* 객체)로 컴파일하고,
> [커널](https://docs.nvidia.com/cuda/cuda-c-programming-guide/#kernels)에서 도입된 `<<<...>>>` 구문([실행 구성](https://docs.nvidia.com/cuda/cuda-c-programming-guide/#execution-configuration)에서 더 자세히 설명됨)을 필요한 CUDA 런타임 함수 호출로 교체하여 호스트 코드를 수정하고 각 컴파일된 커널을 *PTX* 코드 및/또는 *cubin* 객체에서 로드하고 실행합니다.

수정된 호스트 코드는 다른 도구를 사용하여 컴파일할 C++ 코드로 출력되거나, `nvcc`가 마지막 컴파일 단계에서 호스트 컴파일러를 호출하여 직접 객체 코드로 출력됩니다.

응용 프로그램은 다음과 같이 할 수 있습니다:

> 컴파일된 호스트 코드에 링크하거나(가장 일반적인 경우),
> 수정된 호스트 코드를 무시하고(있는 경우) CUDA 드라이버 API([드라이버 API](https://docs.nvidia.com/cuda/cuda-c-programming-guide/#driver-api) 참조)를 사용하여 *PTX* 코드 또는 *cubin* 객체를 로드하고 실행합니다.

#### 3.1.1.2. Just-in-Time 컴파일

애플리케이션이 실행 시간에 로드한 모든 *PTX* 코드는 장치 드라이버에 의해 이진 코드로 추가 컴파일됩니다. 이를 *즉시 컴파일(just-in-time compilation)*이라고 합니다. just-in-time compilation은 애플리케이션의 로드 시간을 증가시키지만, 애플리케이션이 각 새로운 장치 드라이버와 함께 제공되는 새로운 컴파일러 개선의 혜택을 누릴 수 있게 합니다. 또한, 애플리케이션이 컴파일될 당시 존재하지 않았던 장치에서 실행될 수 있는 유일한 방법이기도 합니다([애플리케이션 호환성](https://docs.nvidia.com/cuda/cuda-c-programming-guide/#application-compatibility) 참조).

장치 드라이버가 애플리케이션을 위해 *PTX* 코드를 즉시 컴파일할 때, 후속 애플리케이션 호출에서 컴파일을 반복하지 않도록 생성된 이진 코드의 복사본을 자동으로 캐시합니다. 이 캐시는 *컴퓨트 캐시(compute cache)*라고 하며, 장치 드라이버가 업그레이드될 때 자동으로 무효화되어 애플리케이션이 장치 드라이버에 내장된 새로운 즉시 컴파일러의 개선 사항을 활용할 수 있게 합니다.

즉시 컴파일을 제어하기 위한 환경 변수가 있으며, 이는 [CUDA 환경 변수](https://docs.nvidia.com/cuda/cuda-c-programming-guide/#env-vars)에서 설명됩니다.

CUDA C++ 디바이스 코드를 컴파일하기 위해 `nvcc`를 사용하는 대신, NVRTC를 사용하여 런타임에 CUDA C++ 디바이스 코드를 PTX로 컴파일할 수 있습니다. NVRTC는 CUDA C++를 위한 런타임 컴파일 라이브러리이며, 더 많은 정보는 NVRTC 사용자 가이드에서 확인할 수 있습니다.

### 3.1.2. 이진 호환성

이진 코드는 아키텍처에 따라 다릅니다. *cubin* 객체는 대상 아키텍처를 지정하는 컴파일러 옵션 `-code`를 사용하여 생성됩니다. 예를 들어, `-code=sm_80`으로 컴파일하면 컴퓨트 능력 8.0을 가진 장치용 이진 코드가 생성됩니다. 이진 호환성은 한 minor 수정에서 다음 minor 수정으로 보장되지만, 한 minor 수정에서 이전 minor 수정으로 또는 major 수정 간에는 보장되지 않습니다. 다시 말해, 컴퓨트 능력 *X.y*에 대해 생성된 *cubin* 객체는 컴퓨트 능력 *X.z*를 가진 장치에서만 실행될 수 있으며, 여기서 *z≥y*입니다.

> [Note]
> 이진 호환성은 데스크톱에서만 지원됩니다. Tegra에서는 지원되지 않습니다. 또한, 데스크톱과 Tegra 간의 이진 호환성은 지원되지 않습니다.

### 3.1.3. PTX 호환성

일부 *PTX* 명령어는 더 높은 컴퓨트 능력을 가진 장치에서만 지원됩니다. 예를 들어, [Warp Shuffle Functions](https://docs.nvidia.com/cuda/cuda-c-programming-guide/#warp-shuffle-functions)는 컴퓨트 능력 5.0 이상의 장치에서만 지원됩니다. `-arch` 컴파일러 옵션은 C++를 *PTX* 코드로 컴파일할 때 가정되는 컴퓨트 능력을 지정합니다. 따라서 예를 들어 warp shuffle을 포함하는 코드는 `-arch=compute_50`(또는 그 이상)으로 컴파일되어야 합니다.

특정 컴퓨트 능력을 위해 생성된 *PTX* 코드는 항상 더 크거나 같은 컴퓨트 능력의 이진 코드로 컴파일될 수 있습니다. 이전 *PTX* 버전에서 컴파일된 이진 파일은 일부 하드웨어 기능을 사용하지 못할 수 있습니다. 예를 들어, 컴퓨트 능력 6.0(파스칼)에서 생성된 *PTX*로부터 컴파일된 컴퓨트 능력 7.0(볼타) 장치를 대상으로 하는 이진 파일은 텐서 코어 명령어를 사용하지 못합니다. 이는 파스칼에서 사용할 수 없었기 때문입니다. 결과적으로, 최종 이진 파일은 최신 버전의 *PTX*를 사용하여 생성된 경우보다 성능이 떨어질 수 있습니다.

대상 아키텍처 조건 기능에 맞춰 컴파일된 *PTX* 코드는 정확히 동일한 물리적 아키텍처에서만 실행되며, 다른 곳에서는 실행되지 않습니다. 아키텍처 조건 *PTX* 코드는 이전 및 이후 버전과 호환되지 않습니다. `sm_90a` 또는 `compute_90a`로 컴파일된 예제 코드는 컴퓨트 능력 9.0을 가진 장치에서만 실행되며, 이전 또는 이후 버전과 호환되지 않습니다.

### 3.1.4. 애플리케이션 호환성

특정 컴퓨트 능력을 가진 장치에서 코드를 실행하기 위해, 애플리케이션은 이 컴퓨트 능력과 호환되는 이진 또는 *PTX* 코드를 로드해야 합니다(이진 호환성 및 PTX 호환성 참조). 특히, 더 높은 컴퓨트 능력을 가진 미래 아키텍처에서 코드를 실행할 수 있도록 하려면(아직 이진 코드를 생성할 수 없는 경우), 애플리케이션은 이러한 장치에 대해 즉시 컴파일될 *PTX* 코드를 로드해야 합니다(즉시 컴파일 참조).

어떤 *PTX* 및 이진 코드가 CUDA C++ 애플리케이션에 포함되는지는 `nvcc` 사용자 매뉴얼에 자세히 설명된 `-arch` 및 `-code` 컴파일러 옵션 또는 `-gencode` 컴파일러 옵션에 의해 제어됩니다. 예를 들어,

```bash
nvcc x.cu
        -gencode arch=compute_50,code=sm_50
        -gencode arch=compute_60,code=sm_60
        -gencode arch=compute_70,code=\"compute_70,sm_70\"
```

컴퓨트 능력 5.0 및 6.0과 호환되는 이진 코드(첫 번째 및 두 번째 `-gencode` 옵션)와 컴퓨트 능력 7.0과 호환되는 PTX 및 이진 코드(세 번째 `-gencode` 옵션)를 포함합니다.

호스트 코드는 런타임에 로드하고 실행할 가장 적합한 코드를 자동으로 선택하도록 생성됩니다. 위의 예에서 이는 다음과 같습니다:

> 컴퓨트 능력 5.0 및 5.2를 가진 장치용 5.0 이진 코드,
> 컴퓨트 능력 6.0 및 6.1을 가진 장치용 6.0 이진 코드,
> 컴퓨트 능력 7.0 및 7.5를 가진 장치용 7.0 이진 코드,
> 컴퓨트 능력 8.0 및 8.6을 가진 장치용 런타임에서 이진 코드로 컴파일되는 PTX 코드.

`x.cu`는 예를 들어, 컴퓨트 능력 8.0 이상에서만 지원되는 warp reduction 작업을 사용하는 최적화된 코드 경로를 가질 수 있습니다. `__CUDA_ARCH__` 매크로는 컴퓨트 능력에 따라 다양한 코드 경로를 구분하는 데 사용할 수 있습니다. 이 매크로는 디바이스 코드에 대해서만 정의됩니다. 예를 들어, `-arch=compute_80`으로 컴파일할 때 `__CUDA_ARCH__`는 `800`과 같습니다.

만약 `x.cu`가 `sm_90a` 또는 `compute_90a`와 같은 [아키텍처 조건 기능](https://docs.nvidia.com/cuda/cuda-c-programming-guide/#feature-availability)을 위해 컴파일되면, 이 코드는 컴퓨트 능력 9.0을 가진 장치에서만 실행될 수 있습니다.

드라이버 API를 사용하는 애플리케이션은 코드를 별도의 파일로 컴파일하고 런타임에 가장 적합한 파일을 명시적으로 로드하고 실행해야 합니다.

Volta 아키텍처는 *독립 스레드 스케줄링(Independent Thread Scheduling)*을 도입하여 GPU에서 스레드가 스케줄링되는 방식을 변경합니다. 이전 아키텍처에서 [SIMT 스케줄링](https://docs.nvidia.com/cuda/cuda-c-programming-guide/#simt-architecture)의 특정 동작에 의존하는 코드는 독립 스레드 스케줄링으로 인해 참여하는 스레드 집합이 변경되어 잘못된 결과를 초래할 수 있습니다. [독립 스레드 스케줄링](https://docs.nvidia.com/cuda/cuda-c-programming-guide/#independent-thread-scheduling-7-x)에서 자세히 설명된 수정 작업을 구현하는 동안 마이그레이션을 돕기 위해, Volta 개발자는 컴파일러 옵션 조합 `-arch=compute_60 -code=sm_70`을 사용하여 Pascal의 스레드 스케줄링을 선택할 수 있습니다.

`nvcc` 사용자 매뉴얼은 `-arch`, `-code` 및 `-gencode` 컴파일러 옵션에 대한 다양한 약어를 나열합니다. 예를 들어, `-arch=sm_70`은 `-arch=compute_70 -code=compute_70,sm_70`의 약어이며(이는 `-gencode arch=compute_70,code=\"compute_70,sm_70\"`와 동일합니다).

### 3.1.5. C++ 호환성

컴파일러의 전처리는 C++ 구문 규칙에 따라 CUDA 소스 파일을 처리합니다. 호스트 코드에 대해서는 전체 C++가 지원됩니다. 그러나 디바이스 코드에 대해서는 [C++ 언어 지원](https://docs.nvidia.com/cuda/cuda-c-programming-guide/#c-cplusplus-language-support)에서 설명된 바와 같이 C++의 일부 집합만 완전히 지원됩니다.

### 3.1.6. 64비트 호환성

64비트 버전의 `nvcc`는 장치 코드를 64비트 모드에서 컴파일합니다(즉, 포인터는 64비트입니다). 64비트 모드에서 컴파일된 디바이스 코드는 64비트 모드에서 컴파일된 호스트 코드와만 지원됩니다.