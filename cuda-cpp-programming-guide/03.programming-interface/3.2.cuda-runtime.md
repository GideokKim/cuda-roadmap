## 3.2. CUDA 런타임

런타임은 `cudart` 라이브러리에 구현되어 있으며, 이는 애플리케이션에 정적으로는 `cudart.lib` 또는 `libcudart.a`를 통해, 동적으로는 `cudart.dll` 또는 `libcudart.so`를 통해 연결됩니다. 동적 링크를 위해 `cudart.dll` 및/또는 `cudart.so`가 필요한 애플리케이션은 일반적으로 이를 애플리케이션 설치 패키지의 일부로 포함합니다. CUDA 런타임 심볼의 주소를 전달하는 것은 동일한 CUDA 런타임 인스턴스에 링크된 구성 요소 간에서만 안전합니다.

모든 진입점은 `cuda`로 접두사가 붙습니다.

[이종 프로그래밍](https://docs.nvidia.com/cuda/cuda-c-programming-guide/#heterogeneous-programming)에서 언급했듯이, CUDA 프로그래밍 모델은 호스트와 디바이스로 구성된 시스템을 가정하며, 각 시스템은 별도의 메모리를 가지고 있습니다. [디바이스 메모리](https://docs.nvidia.com/cuda/cuda-c-programming-guide/#device-memory)는 디바이스 메모리를 관리하는 데 사용되는 런타임 함수에 대한 개요를 제공합니다.

[공유 메모리](https://docs.nvidia.com/cuda/cuda-c-programming-guide/#shared-memory)는 성능을 극대화하기 위해 [스레드 계층](https://docs.nvidia.com/cuda/cuda-c-programming-guide/#thread-hierarchy)에서 도입된 공유 메모리의 사용을 설명합니다.

[페이지 잠금 호스트 메모리](https://docs.nvidia.com/cuda/cuda-c-programming-guide/#page-locked-host-memory)는 호스트와 디바이스 메모리 간의 데이터 전송과 커널 실행을 겹치게 하는 데 필요한 페이지 잠금 호스트 메모리를 소개합니다.

[비동기 동시 실행](https://docs.nvidia.com/cuda/cuda-c-programming-guide/#asynchronous-concurrent-execution)은 시스템의 다양한 수준에서 비동기 동시 실행을 가능하게 하는 개념과 API를 설명합니다.

[다중 장치 시스템](https://docs.nvidia.com/cuda/cuda-c-programming-guide/#multi-device-system)은 프로그래밍 모델이 동일한 호스트에 연결된 여러 디바이스가 있는 시스템으로 확장되는 방법을 보여줍니다.

[오류 검사](https://docs.nvidia.com/cuda/cuda-c-programming-guide/#error-checking)는 런타임에서 생성된 오류를 올바르게 확인하는 방법을 설명합니다.

[호출 스택](https://docs.nvidia.com/cuda/cuda-c-programming-guide/#call-stack)은 CUDA C++ 호출 스택을 관리하는 데 사용되는 런타임 함수를 언급합니다.

[텍스처 및 서피스 메모리](https://docs.nvidia.com/cuda/cuda-c-programming-guide/#texture-and-surface-memory)는 디바이스 메모리에 접근하는 또 다른 방법을 제공하는 텍스처 및 서피스 메모리 공간을 소개하며, GPU 텍스처링 하드웨어의 하위 집합도 노출합니다.

[그래픽 상호 운용성](https://docs.nvidia.com/cuda/cuda-c-programming-guide/#graphics-interoperability)은 런타임이 OpenGL 및 Direct3D라는 두 가지 주요 그래픽 API와 상호 작용하기 위해 제공하는 다양한 기능을 소개합니다.

### 3.2.1. 초기화

CUDA 12.0부터, `cudaInitDevice()` 및 `cudaSetDevice()` 호출은 런타임과 지정된 디바이스와 관련된 기본 컨텍스트를 초기화합니다. 이러한 호출이 없으면, 런타임은 암묵적으로 디바이스 0을 사용하고 다른 런타임 API 요청을 처리하기 위해 필요에 따라 자동으로 초기화됩니다. 런타임 함수 호출의 타이밍을 측정하거나 런타임에 대한 첫 번째 호출에서 오류 코드를 해석할 때 이 점을 염두에 두어야 합니다. 12.0 이전에는 `cudaSetDevice()`가 런타임을 초기화하지 않았으며, 애플리케이션은 종종 타이밍과 오류 처리를 위해 런타임 초기화를 다른 API 활동과 분리하기 위해 `cudaFree(0)`와 같은 무작위 호출을 사용했습니다.

런타임은 시스템의 각 장치에 대해 CUDA 컨텍스트를 생성합니다(자세한 내용은 [컨텍스트](https://docs.nvidia.com/cuda/cuda-c-programming-guide/#context)를 참조하십시오). 이 컨텍스트는 해당 장치의 *기본 컨텍스트*이며, 이 장치에서 활성 컨텍스트가 필요한 첫 번째 런타임 함수에서 초기화됩니다. 이 컨텍스트는 애플리케이션의 모든 호스트 스레드 간에 공유됩니다. 이 컨텍스트 생성의 일환으로, 필요할 경우 디바이스 코드는 즉시 컴파일되어(자세한 내용은 [즉시 컴파일](https://docs.nvidia.com/cuda/cuda-c-programming-guide/#just-in-time-compilation) 참조) 디바이스 메모리에 로드됩니다. 이 모든 과정은 투명하게 이루어집니다. 필요할 경우, 예를 들어 드라이버 API 상호 운용성을 위해, 장치의 기본 컨텍스트는 [런타임과 드라이버 API 간의 상호 운용성](https://docs.nvidia.com/cuda/cuda-c-programming-guide/#interoperability-between-runtime-and-driver-apis)에서 설명된 대로 드라이버 API를 통해 접근할 수 있습니다.

호스트 스레드가 `cudaDeviceReset()`를 호출하면, 이는 호스트 스레드가 현재 작업 중인 디바이스의 기본 컨텍스트를 파괴합니다(즉, [장치 선택](https://docs.nvidia.com/cuda/cuda-c-programming-guide/#device-selection)에서 정의된 현재 장치). 이 디바이스를 현재 디바이스로 가진 호스트 스레드가 다음으로 호출하는 런타임 함수는 이 디바이스에 대한 새로운 기본 컨텍스트를 생성합니다.

> 주의
> CUDA 인터페이스는 호스트 프로그램 초기화 중에 초기화되고 호스트 프로그램 종료 중에 파괴되는 전역 상태를 사용합니다. CUDA 런타임과 드라이버는 이 상태가 유효하지 않은지 감지할 수 없으므로, 프로그램 초기화 또는 종료 중에 이러한 인터페이스(암묵적으로 또는 명시적으로)를 사용하면 정의되지 않은 동작이 발생합니다.
> CUDA 12.0부터, `cudaSetDevice()`는 이제 호스트 스레드의 현재 디바이스를 변경한 후 런타임을 명시적으로 초기화합니다. 이전 버전의 CUDA는 `cudaSetDevice()` 호출 후 첫 번째 런타임 호출이 이루어질 때까지 새로운 디바이스에서 런타임 초기화를 지연시켰습니다. 이 변경은 이제 `cudaSetDevice()`의 반환 값을 초기화 오류에 대해 확인하는 것이 매우 중요하다는 것을 의미합니다.
> 참조 매뉴얼의 오류 처리 및 버전 관리 섹션의 런타임 함수는 런타임을 초기화하지 않습니다.