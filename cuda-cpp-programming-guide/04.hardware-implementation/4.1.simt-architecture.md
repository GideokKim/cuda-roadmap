## 4.1. SIMT Architecture

멀티프로세서는 32개의 병렬 스레드 그룹인 *워프(warp)*를 생성, 관리, 스케줄링 및 실행합니다. 워프를 구성하는 개별 스레드는 동일한 프로그램 주소에서 함께 시작하지만, 각 스레드는 고유한 명령어 주소 카운터와 레지스터 상태를 가지므로 독립적으로 분기하고 실행할 수 있습니다. *"워프"*라는 용어는 최초의 병렬 스레드 기술인 직조(weaving)에서 유래되었습니다. *반 워프(half-warp)*는 워프의 첫 번째 또는 두 번째 절반을 의미합니다. *쿼터 워프(quarter-warp)*는 워프의 첫 번째, 두 번째, 세 번째 또는 네 번째 쿼터를 의미합니다.

멀티프로세서가 실행할 하나 이상의 스레드 블록을 받으면, 이를 워프로 분할하고 각 워프는 실행을 위해 워프 스케줄러에 의해 스케줄됩니다. 블록이 워프로 분할되는 방식은 항상 동일하며, 각 워프는 연속적이고 증가하는 스레드 ID를 가진 스레드를 포함하며, 첫 번째 워프는 스레드 0을 포함합니다. [스레드 계층](https://docs.nvidia.com/cuda/cuda-c-programming-guide/#thread-hierarchy)은 스레드 ID가 블록 내의 스레드 인덱스와 어떻게 관련되는지를 설명합니다.

워프는 한 번에 하나의 공통 명령어를 실행하므로, 모든 32개의 스레드가 실행 경로에 동의할 때 최대 효율이 실현됩니다. 만약 워프의 스레드가 데이터 종속 조건 분기를 통해 분기하면, 워프는 각 분기 경로를 실행하며 해당 경로에 있지 않은 스레드는 비활성화됩니다. 분기 발산은 오직 워프 내에서만 발생하며, 서로 다른 워프는 공통 코드 경로 또는 분리된 코드 경로를 실행하더라도 독립적으로 실행됩니다.

SIMT 아키텍처는 단일 명령어가 여러 처리 요소를 제어한다는 점에서 SIMD(Single Instruction, Multiple Data) 벡터 조직과 유사합니다. 주요 차이점은 SIMD 벡터 조직이 SIMD 폭을 소프트웨어에 노출하는 반면, SIMT 명령어는 단일 스레드의 실행 및 분기 동작을 지정한다는 것입니다. SIMD 벡터 머신과 대조적으로, SIMT는 프로그래머가 독립적인 스칼라 스레드에 대한 스레드 수준 병렬 코드와 조정된 스레드에 대한 데이터 병렬 코드를 작성할 수 있게 합니다. 정확성을 위해 프로그래머는 본질적으로 SIMT 동작을 무시할 수 있지만, 코드가 워프 내의 스레드가 분기할 필요가 거의 없도록 주의함으로써 상당한 성능 향상을 실현할 수 있습니다. 실제로 이는 전통적인 코드에서 캐시 라인의 역할과 유사합니다: 정확성을 위해 설계할 때 캐시 라인 크기는 안전하게 무시할 수 있지만, 최대 성능을 위해 설계할 때는 코드 구조에서 고려해야 합니다. 반면, 벡터 아키텍처는 소프트웨어가 로드를 벡터로 집합하고 분기를 수동으로 관리하도록 요구합니다.

NVIDIA Volta 이전에는 워프가 모든 32개의 스레드가 공유하는 단일 프로그램 카운터와 워프의 활성 스레드를 지정하는 활성 마스크를 사용했습니다. 그 결과, 분기된 영역이나 서로 다른 실행 상태에 있는 동일한 워프의 스레드는 서로 신호를 보내거나 데이터를 교환할 수 없으며, 잠금이나 뮤텍스에 의해 보호되는 데이터의 세밀한 공유를 요구하는 알고리즘은 경쟁하는 스레드가 어떤 워프에서 오는지에 따라 쉽게 교착 상태에 빠질 수 있습니다.

NVIDIA Volta 아키텍처부터는 *독립 스레드 스케줄링(Independent Thread Scheduling)*을 통해 워프에 관계없이 스레드 간의 완전한 동시성이 허용됩니다. 독립 스레드 스케줄링을 사용하면 GPU는 각 스레드에 대한 실행 상태(프로그램 카운터 및 호출 스택 포함)를 유지하며, 실행 자원을 더 잘 활용하거나 한 스레드가 다른 스레드에 의해 생성된 데이터를 기다릴 수 있도록 스레드 단위로 실행을 양보할 수 있습니다. 스케줄 최적화기는 동일한 워프의 활성 스레드를 SIMT 단위로 그룹화하는 방법을 결정합니다. 이는 이전 NVIDIA GPU와 마찬가지로 SIMT 실행의 높은 처리량을 유지하지만, 훨씬 더 많은 유연성을 제공합니다: 이제 스레드는 서브 워프 단위로 분기하고 다시 수렴할 수 있습니다.

독립 스레드 스케줄링(Independent Thread Scheduling)은 개발자가 이전 하드웨어 아키텍처의 워프 동기성에 대한 가정을 했다면, 실행된 코드에 참여하는 스레드 집합이 의도한 것과 상당히 다를 수 있습니다. 특히, 모든 워프 동기 코드(예: synchronization-free, intra-warp reductions)는 NVIDIA Volta 및 그 이후 버전과의 호환성을 보장하기 위해 다시 검토해야 합니다. 자세한 내용은 [컴퓨트 능력 7.x](https://docs.nvidia.com/cuda/cuda-c-programming-guide/#compute-capability-7-x)를 참조하십시오.

> 주의
> 현재 명령어에 참여하고 있는 워프의 스레드는 *활성 스레드(active threads)*라고 하며, 현재 명령어에 참여하지 않는 스레드는 *비활성 스레드(inactive, disabled)*라고 합니다. 스레드가 비활성 상태가 되는 이유는 여러 가지가 있으며, 그 중에는 워프의 다른 스레드보다 먼저 종료되었거나, 현재 워프에서 실행 중인 분기 경로와 다른 분기 경로를 선택했거나, 스레드 수가 워프 크기의 배수가 아닌 블록의 마지막 스레드일 경우가 포함됩니다.
> 워프에 의해 실행된 비원자(non-atomic) 명령어 수행으로 워프의 여러 스레드가 동일한 전역 또는 공유 메모리 위치에 쓰기를 수행하는 경우, 해당 위치에 발생하는 직렬화된 쓰기 수는 장치의 컴퓨트 능력에 따라 달라집니다(자세한 내용은 [컴퓨트 능력 5.x](https://docs.nvidia.com/cuda/cuda-c-programming-guide/#compute-capability-5-x), [컴퓨트 능력 6.x](https://docs.nvidia.com/cuda/cuda-c-programming-guide/#compute-capability-6-x), [컴퓨트 능력 7.x](https://docs.nvidia.com/cuda/cuda-c-programming-guide/#compute-capability-7-x) 참조). 마지막 쓰기를 수행하는 스레드는 정의되지 않습니다.
> 워프에 의해 실행된 [원자(atomic)](https://docs.nvidia.com/cuda/cuda-c-programming-guide/#atomic-functions) 명령어 수행으로 워프의 여러 스레드가 동일한 전역 메모리 위치를 읽고 수정하며 쓰기를 수행하는 경우, 해당 위치에 대한 각 읽기/수정/쓰기가 발생하며 모두 직렬화되지만, 이들이 발생하는 순서는 정의되지 않습니다.