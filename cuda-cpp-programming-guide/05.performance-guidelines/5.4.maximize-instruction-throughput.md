## 5.4 명령어 처리량 최대화

명령어 처리량을 최대화하기 위해 애플리케이션은 다음을 수행해야 합니다:

- 처리량이 낮은 산술 명령어의 사용을 최소화합니다. 여기에는 최종 결과에 영향을 미치지 않는 경우 정밀도를 속도와 교환하는 것이 포함됩니다:
  - 일반 함수 대신 내장 함수 사용 (내장 함수는 [내장 함수 섹션](https://docs.nvidia.com/cuda/cuda-c-programming-guide/#mathematical-functions-appendix-intrinsic-functions)에 나열됨)
  - 배정밀도 대신 단정밀도 사용
  - 비정규화된 숫자를 0으로 플러시
- [제어 흐름 명령어](https://docs.nvidia.com/cuda/cuda-c-programming-guide/#control-flow-instructions)에서 설명한 대로 제어 흐름 명령어로 인한 워프 분기를 최소화
- 명령어 수를 줄입니다. 예를 들어:
  - [동기화 명령어](https://docs.nvidia.com/cuda/cuda-c-programming-guide/#synchronization-instruction)에서 설명한 대로 가능한 경우 동기화 지점을 최적화
  - `__restrict__`에서 설명한 대로 제한된 포인터 사용

이 섹션에서 처리량은 멀티프로세서당 클럭 사이클당 연산 수로 표시됩니다. 워프 크기가 32인 경우, 하나의 명령어는 32개의 연산에 해당하므로, N이 클럭 사이클당 연산 수라면 명령어 처리량은 클럭 사이클당 N/32 명령어입니다.

모든 처리량은 하나의 멀티프로세서에 대한 것입니다. 디바이스 전체의 처리량을 얻으려면 디바이스의 멀티프로세서 수를 곱해야 합니다.

### 5.4.1 산술 명령어

다음 표는 다양한 컴퓨트 능력을 가진 디바이스에서 하드웨어에서 기본적으로 지원되는 산술 명령어의 처리량을 보여줍니다.

표 4. [기본 산술 명령어의 처리량 (멀티프로세서당 클럭 사이클당 결과 수)](https://docs.nvidia.com/cuda/cuda-c-programming-guide/#arithmetic-instructions-throughput-native-arithmetic-instructions)

다른 명령어와 함수들은 기본 명령어 위에 구현됩니다. 구현은 디바이스의 컴퓨트 능력에 따라 다를 수 있으며, 컴파일 후 기본 명령어의 수는 컴파일러 버전마다 달라질 수 있습니다. 복잡한 함수의 경우 입력에 따라 여러 코드 경로가 있을 수 있습니다. `cuobjdump`를 사용하여 `cubin` 객체의 특정 구현을 검사할 수 있습니다.

일부 함수의 구현은 CUDA 헤더 파일(`math_functions.h`, `device_functions.h`, ...)에서 바로 확인할 수 있습니다.

일반적으로 `-ftz=true`(비정규화된 숫자를 0으로 플러시)로 컴파일된 코드는 `-ftz=false`로 컴파일된 코드보다 성능이 더 높은 경향이 있습니다. 마찬가지로 `-prec-div=false`(덜 정밀한 나눗셈)로 컴파일된 코드는 `-prec-div=true`로 컴파일된 코드보다 성능이 더 높은 경향이 있으며, `-prec-sqrt=false`(덜 정밀한 제곱근)로 컴파일된 코드는 `-prec-sqrt=true`로 컴파일된 코드보다 성능이 더 높은 경향이 있습니다. nvcc 사용자 매뉴얼에서 이러한 컴파일 플래그에 대해 자세히 설명합니다.

#### 단정밀도 부동소수점 나눗셈

`__fdividef(x, y)`([내장 함수](https://docs.nvidia.com/cuda/cuda-c-programming-guide/#mathematical-functions-appendix-intrinsic-functions) 참조)는 나눗셈 연산자보다 더 빠른 단정밀도 부동소수점 나눗셈을 제공합니다.

#### 단정밀도 부동소수점 역제곱근

IEEE-754 의미를 보존하기 위해 컴파일러는 역수와 제곱근이 모두 근사값일 때만(`-prec-div=false`와 `-prec-sqrt=false`) `1.0/sqrtf()`를 `rsqrtf()`로 최적화할 수 있습니다. 따라서 필요한 경우 `rsqrtf()`를 직접 호출하는 것이 권장됩니다.

#### 단정밀도 부동소수점 제곱근

단정밀도 부동소수점 제곱근은 역제곱근 후 곱셈이 아닌 역제곱근 후 역수로 구현되어 0과 무한대에 대해 올바른 결과를 제공합니다.

#### 사인과 코사인

`sinf(x)`, `cosf(x)`, `tanf(x)`, `sincosf(x)` 및 해당하는 배정밀도 명령어는 매우 비용이 많이 들며, 특히 인수 x의 크기가 큰 경우 더욱 그렇습니다.

더 자세히 말하면, 인수 축소 코드(구현은 [수학 함수](https://docs.nvidia.com/cuda/cuda-c-programming-guide/#mathematical-functions-appendix) 참조)는 각각 빠른 경로와 느린 경로라고 하는 두 가지 코드 경로로 구성됩니다.

빠른 경로는 크기가 충분히 작은 인수에 사용되며 기본적으로 몇 개의 곱셈-덧셈 연산으로 구성됩니다. 느린 경로는 크기가 큰 인수에 사용되며 전체 인수 범위에 걸쳐 올바른 결과를 얻기 위해 필요한 긴 계산으로 구성됩니다.

현재 삼각함수의 인수 축소 코드는 단정밀도 함수의 경우 크기가 `105615.0f` 미만인 인수에 대해, 배정밀도 함수의 경우 크기가 `2147483648.0` 미만인 인수에 대해 빠른 경로를 선택합니다.

느린 경로는 빠른 경로보다 더 많은 레지스터가 필요하므로, 일부 중간 변수를 로컬 메모리에 저장하여 느린 경로의 레지스터 압력을 줄이려는 시도가 있었습니다. 이는 로컬 메모리의 높은 지연 시간과 대역폭으로 인해 성능에 영향을 미칠 수 있습니다([디바이스 메모리 접근](https://docs.nvidia.com/cuda/cuda-c-programming-guide/#device-memory-accesses) 참조). 현재 단정밀도 함수는 28바이트의 로컬 메모리를 사용하고, 배정밀도 함수는 44바이트를 사용합니다. 하지만 정확한 양은 변경될 수 있습니다.

느린 경로의 긴 계산과 로컬 메모리 사용으로 인해, 느린 경로 축소가 필요한 경우 이러한 삼각함수의 처리량은 빠른 경로 축소에 비해 한 자릿수 정도 낮습니다.

#### 정수 산술

정수 나눗셈과 모듈로 연산은 최대 20개의 명령어로 컴파일되므로 비용이 많이 듭니다. 일부 경우에는 비트 연산으로 대체할 수 있습니다: `n`이 2의 거듭제곱인 경우, `(i/n)`은 `(i>>log2(n))`과 동일하고 `(i%n)`은 `(i&(n-1))`과 동일합니다. `n`이 리터럴인 경우 컴파일러가 이러한 변환을 수행합니다.

`__brev`와 `__popc`는 단일 명령어로 매핑되고 `__brevll`과 `__popcll`은 몇 개의 명령어로 매핑됩니다.

`__[u]mul24`는 더 이상 사용할 이유가 없는 레거시 내장 함수입니다.

#### 반정밀도 산술

16비트 정밀도 부동소수점 덧셈, 곱셈 또는 곱셈-덧셈에서 좋은 성능을 얻기 위해서는 `half` 정밀도에는 `half2` 데이터 타입을, `__nv_bfloat16` 정밀도에는 `__nv_bfloat162`를 사용하는 것이 권장됩니다. 벡터 내장 함수(예: `__hadd2`, `__hsub2`, `__hmul2`, `__hfma2`)를 사용하여 단일 명령어로 두 개의 연산을 수행할 수 있습니다. `half` 또는 `__nv_bfloat16`을 사용하는 두 번의 호출 대신 `half2` 또는 `__nv_bfloat162`를 사용하면 워프 셔플과 같은 다른 내장 함수의 성능도 향상될 수 있습니다.

두 개의 `half` 정밀도 값을 `half2` 데이터 타입으로 변환하기 위해 `__halves2half2` 내장 함수가 제공됩니다.

두 개의 `__nv_bfloat16` 정밀도 값을 `__nv_bfloat162` 데이터 타입으로 변환하기 위해 `__halves2bfloat162` 내장 함수가 제공됩니다.

#### 타입 변환

때로는 컴파일러가 변환 명령어를 삽입해야 하며, 이는 추가적인 실행 사이클을 도입합니다. 이는 다음과 같은 경우에 해당합니다:

- `char` 또는 `short` 타입의 변수에 대해 작동하는 함수의 피연산자는 일반적으로 `int`로 변환되어야 함
- 단정밀도 부동소수점 계산의 입력으로 사용되는 배정밀도 부동소수점 상수(즉, 타입 접미사 없이 정의된 상수)(C/C++ 표준에 의해 요구됨)

마지막 경우는 `f` 접미사를 사용하여 정의된 단정밀도 부동소수점 상수(예: `3.141592653589793f`, `1.0f`, `0.5f`)를 사용하여 피할 수 있습니다.

### 5.4.2 제어 흐름 명령어

모든 흐름 제어 명령어(`if`, `switch`, `do`, `for`, `while`)는 동일한 워프의 스레드가 분기하게(즉, 다른 실행 경로를 따르게) 함으로써 유효 명령어 처리량에 상당한 영향을 미칠 수 있습니다. 이 경우 서로 다른 실행 경로를 직렬화해야 하므로 이 워프에 대해 실행되는 총 명령어 수가 증가합니다.

제어 흐름이 스레드 ID에 따라 달라지는 경우 최상의 성능을 얻으려면, 분기하는 워프의 수를 최소화하도록 제어 조건을 작성해야 합니다. 이는 [SIMT 아키텍처](https://docs.nvidia.com/cuda/cuda-c-programming-guide/#simt-architecture)에서 언급한 대로 블록 전체의 워프 분포가 결정적이기 때문에 가능합니다. 간단한 예로, 제어 조건이 (`threadIdx / warpSize`)에만 의존하는 경우입니다. 여기서 `warpSize`는 워프 크기입니다. 이 경우 제어 조건이 워프와 완벽하게 정렬되어 있으므로 워프가 분기하지 않습니다.

때로는 컴파일러가 루프를 펼치거나 아래에서 자세히 설명하는 것처럼 분기 예측을 사용하여 짧은 `if` 또는 `switch` 블록을 최적화할 수 있습니다. 이러한 경우에는 워프가 절대 분기하지 않습니다. 프로그래머는 또한 `#pragma unroll` 지시문을 사용하여 루프 펼침을 제어할 수 있습니다([#pragma unroll](https://docs.nvidia.com/cuda/cuda-c-programming-guide/#pragma-unroll) 참조).

분기 예측을 사용할 때는 실행이 제어 조건에 따라 달라지는 명령어 중 어느 것도 건너뛰지 않습니다. 대신, 각 명령어는 제어 조건에 따라 true 또는 false로 설정되는 스레드별 조건 코드 또는 술어와 연결되며, 이러한 각 명령어가 실행을 위해 스케줄링되지만 술어가 true인 명령어만 실제로 실행됩니다. 술어가 false인 명령어는 결과를 쓰지 않으며, 주소를 평가하거나 피연산자를 읽지도 않습니다.

## 5.4.3 동기화 명령어

`__syncthreads()`의 처리량은 컴퓨트 능력 6.0 디바이스의 경우 클럭 사이클당 32개 연산, 컴퓨트 능력 7.x 및 8.x 디바이스의 경우 클럭 사이클당 16개 연산, 컴퓨트 능력 5.x, 6.1 및 6.2 디바이스의 경우 클럭 사이클당 64개 연산입니다.

`__syncthreads()`는 [디바이스 메모리 접근](https://docs.nvidia.com/cuda/cuda-c-programming-guide/#device-memory-accesses)에서 설명한 대로 멀티프로세서를 유휴 상태로 만들어 성능에 영향을 미칠 수 있습니다.